job is running on xgph4, started at Thu Mar  6 01:10:52 +08 2025
Training model: roberta

--- Installing packages ---

Defaulting to user installation because normal site-packages is not writeable
Collecting torch
  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 766.7/766.7 MB 3.3 MB/s eta 0:00:00
Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)
Collecting transformers
  Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 18.1 MB/s eta 0:00:00
Collecting scikit-learn
  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 58.3 MB/s eta 0:00:00
Collecting nvidia-nvjitlink-cu12==12.4.127
  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 50.0 MB/s eta 0:00:00
Collecting networkx
  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 6.1 MB/s eta 0:00:00
Collecting fsspec
  Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.5/184.5 KB 4.0 MB/s eta 0:00:00
Collecting nvidia-cuda-runtime-cu12==12.4.127
  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 KB 21.7 MB/s eta 0:00:00
Collecting sympy==1.13.1
  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 75.1 MB/s eta 0:00:00
Collecting nvidia-nvtx-cu12==12.4.127
  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 KB 5.3 MB/s eta 0:00:00
Collecting triton==3.2.0
  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 253.1/253.1 MB 9.5 MB/s eta 0:00:00
Collecting nvidia-cuda-nvrtc-cu12==12.4.127
  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 48.2 MB/s eta 0:00:00
Collecting nvidia-cusparselt-cu12==0.6.2
  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.1/150.1 MB 16.0 MB/s eta 0:00:00
Collecting nvidia-cublas-cu12==12.4.5.8
  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 6.9 MB/s eta 0:00:00
Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)
Collecting nvidia-nccl-cu12==2.21.5
  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 12.1 MB/s eta 0:00:00
Collecting nvidia-cuda-cupti-cu12==12.4.127
  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 57.6 MB/s eta 0:00:00
Collecting nvidia-curand-cu12==10.3.5.147
  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 33.6 MB/s eta 0:00:00
Collecting nvidia-cusparse-cu12==12.3.1.170
  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 12.0 MB/s eta 0:00:00
Collecting nvidia-cudnn-cu12==9.1.0.70
  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 4.1 MB/s eta 0:00:00
Collecting nvidia-cusolver-cu12==11.6.1.9
  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 16.6 MB/s eta 0:00:00
Collecting typing-extensions>=4.10.0
  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting filelock
  Downloading filelock-3.17.0-py3-none-any.whl (16 kB)
Collecting nvidia-cufft-cu12==11.2.1.3
  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 11.3 MB/s eta 0:00:00
Collecting mpmath<1.4,>=1.1.0
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 KB 4.9 MB/s eta 0:00:00
Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)
Collecting tokenizers<0.22,>=0.21
  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 43.6 MB/s eta 0:00:00
Collecting huggingface-hub<1.0,>=0.26.0
  Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.1/468.1 KB 19.7 MB/s eta 0:00:00
Collecting regex!=2019.12.17
  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 KB 35.5 MB/s eta 0:00:00
Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)
Collecting tqdm>=4.27
  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 KB 4.4 MB/s eta 0:00:00
Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers) (1.21.5)
Collecting safetensors>=0.4.1
  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 471.6/471.6 KB 4.9 MB/s eta 0:00:00
Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)
Collecting threadpoolctl>=3.1.0
  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)
Collecting joblib>=1.2.0
  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.8/301.8 KB 11.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.6.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)
Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, tqdm, threadpoolctl, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, fsspec, filelock, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch
Successfully installed filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.2 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0 triton-3.2.0 typing-extensions-4.12.2

--- Finished installing packages, starting model training ---

Running RoBERTa model training...
device: cuda

================ Epoch 1 / 3 ================
  Batch    40  of    624.    Elapsed: 0:00:09.
  Batch    80  of    624.    Elapsed: 0:00:17.
  Batch   120  of    624.    Elapsed: 0:00:25.
  Batch   160  of    624.    Elapsed: 0:00:33.
  Batch   200  of    624.    Elapsed: 0:00:41.
  Batch   240  of    624.    Elapsed: 0:00:49.
  Batch   280  of    624.    Elapsed: 0:00:57.
  Batch   320  of    624.    Elapsed: 0:01:05.
  Batch   360  of    624.    Elapsed: 0:01:13.
  Batch   400  of    624.    Elapsed: 0:01:21.
  Batch   440  of    624.    Elapsed: 0:01:29.
  Batch   480  of    624.    Elapsed: 0:01:37.
  Batch   520  of    624.    Elapsed: 0:01:45.
  Batch   560  of    624.    Elapsed: 0:01:53.
  Batch   600  of    624.    Elapsed: 0:02:01.

---TRAIN METRICS---
Loss: 0.2716
Accuracy: 0.8804
Precision: 0.8696
Recall: 0.8824
F1-Score: 0.8760

Running validation ...


---TEST METRICS---
Loss: 0.1817
Accuracy: 0.9252
Precision: 0.9017
Recall: 0.9427
F1-Score: 0.9218

================ Epoch 2 / 3 ================
  Batch    40  of    624.    Elapsed: 0:00:08.
  Batch    80  of    624.    Elapsed: 0:00:16.
  Batch   120  of    624.    Elapsed: 0:00:24.
  Batch   160  of    624.    Elapsed: 0:00:32.
  Batch   200  of    624.    Elapsed: 0:00:40.
  Batch   240  of    624.    Elapsed: 0:00:48.
  Batch   280  of    624.    Elapsed: 0:00:56.
  Batch   320  of    624.    Elapsed: 0:01:04.
  Batch   360  of    624.    Elapsed: 0:01:12.
  Batch   400  of    624.    Elapsed: 0:01:20.
  Batch   440  of    624.    Elapsed: 0:01:28.
  Batch   480  of    624.    Elapsed: 0:01:36.
  Batch   520  of    624.    Elapsed: 0:01:44.
  Batch   560  of    624.    Elapsed: 0:01:52.
  Batch   600  of    624.    Elapsed: 0:02:00.

---TRAIN METRICS---
Loss: 0.2054
Accuracy: 0.9454
Precision: 0.9421
Recall: 0.9440
F1-Score: 0.9431

Running validation ...


---TEST METRICS---
Loss: 0.2112
Accuracy: 0.9163
Precision: 0.9675
Recall: 0.8495
F1-Score: 0.9047

================ Epoch 3 / 3 ================
  Batch    40  of    624.    Elapsed: 0:00:08.
  Batch    80  of    624.    Elapsed: 0:00:16.
  Batch   120  of    624.    Elapsed: 0:00:24.
  Batch   160  of    624.    Elapsed: 0:00:32.
  Batch   200  of    624.    Elapsed: 0:00:40.
  Batch   240  of    624.    Elapsed: 0:00:48.
  Batch   280  of    624.    Elapsed: 0:00:56.
  Batch   320  of    624.    Elapsed: 0:01:04.
  Batch   360  of    624.    Elapsed: 0:01:12.
  Batch   400  of    624.    Elapsed: 0:01:20.
  Batch   440  of    624.    Elapsed: 0:01:28.
  Batch   480  of    624.    Elapsed: 0:01:37.
  Batch   520  of    624.    Elapsed: 0:01:45.
  Batch   560  of    624.    Elapsed: 0:01:53.
  Batch   600  of    624.    Elapsed: 0:02:01.

---TRAIN METRICS---
Loss: 0.1644
Accuracy: 0.9701
Precision: 0.9673
Recall: 0.9704
F1-Score: 0.9689

Running validation ...


---TEST METRICS---
Loss: 0.1677
Accuracy: 0.9368
Precision: 0.9323
Recall: 0.9327
F1-Score: 0.9325
Model and tokenizer saved to /home/l/linustws/cs4248/Sarcasm-Detection/training_scripts/../models/fine_tuned_roberta
-e 
Job completed at Thu Mar  6 01:22:33 +08 2025

-e total execution time: 456 seconds
