>>> Activating virtualenv...
>>> Python used: /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/cuml-test-env/bin/python
>>> Pip used: /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/cuml-test-env/bin/pip
Requirement already satisfied: pip in ./cuml-test-env/lib/python3.10/site-packages (25.0.1)
Requirement already satisfied: setuptools in ./cuml-test-env/lib/python3.10/site-packages (78.1.0)
Requirement already satisfied: wheel in ./cuml-test-env/lib/python3.10/site-packages (0.45.1)
Found existing installation: dask-cuda 25.4.0
Uninstalling dask-cuda-25.4.0:
  Successfully uninstalled dask-cuda-25.4.0
Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com
Requirement already satisfied: cudf-cu12==25.4.0 in ./cuml-test-env/lib/python3.10/site-packages (25.4.0)
Requirement already satisfied: cuml-cu12==25.4.0 in ./cuml-test-env/lib/python3.10/site-packages (25.4.0)
Requirement already satisfied: rmm-cu12==25.4.0 in ./cuml-test-env/lib/python3.10/site-packages (25.4.0)
Requirement already satisfied: dask-cudf-cu12==25.4.0 in ./cuml-test-env/lib/python3.10/site-packages (25.4.0)
Requirement already satisfied: cupy-cuda12x in ./cuml-test-env/lib/python3.10/site-packages (13.4.1)
Requirement already satisfied: cachetools in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (5.5.2)
Requirement already satisfied: cuda-python<13.0a0,>=12.6.2 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (12.8.0)
Requirement already satisfied: fsspec>=0.6.0 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (2025.3.2)
Requirement already satisfied: libcudf-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (25.4.0)
Requirement already satisfied: numba-cuda<0.5.0a0,>=0.4.0 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (0.4.0)
Requirement already satisfied: numba<0.62.0a0,>=0.59.1 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (0.60.0)
Requirement already satisfied: numpy<3.0a0,>=1.23 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (1.24.4)
Requirement already satisfied: nvtx>=0.2.1 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (0.2.11)
Requirement already satisfied: packaging in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (24.2)
Requirement already satisfied: pandas<2.2.4dev0,>=2.0 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (2.2.3)
Requirement already satisfied: pyarrow<20.0.0a0,>=14.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (19.0.1)
Requirement already satisfied: pylibcudf-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (25.4.0)
Requirement already satisfied: pynvjitlink-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (0.5.2)
Requirement already satisfied: rich in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (14.0.0)
Requirement already satisfied: typing_extensions>=4.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from cudf-cu12==25.4.0) (4.13.2)
Requirement already satisfied: cuvs-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (25.4.0)
Collecting dask-cuda==25.4.* (from cuml-cu12==25.4.0)
  Downloading https://pypi.nvidia.com/dask-cuda/dask_cuda-25.4.0-py3-none-any.whl (135 kB)
Requirement already satisfied: joblib>=0.11 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (1.4.2)
Requirement already satisfied: libcuml-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (25.4.0)
Requirement already satisfied: nvidia-cublas-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (12.4.5.8)
Requirement already satisfied: nvidia-cufft-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (11.2.1.3)
Requirement already satisfied: nvidia-curand-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (10.3.5.147)
Requirement already satisfied: nvidia-cusolver-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (11.6.1.9)
Requirement already satisfied: nvidia-cusparse-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (12.3.1.170)
Requirement already satisfied: pylibraft-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (25.4.0)
Requirement already satisfied: raft-dask-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (25.4.0)
Requirement already satisfied: rapids-dask-dependency==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (25.4.0)
Requirement already satisfied: scipy>=1.8.0 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (1.15.2)
Requirement already satisfied: treelite==4.4.1 in ./cuml-test-env/lib/python3.10/site-packages (from cuml-cu12==25.4.0) (4.4.1)
Requirement already satisfied: librmm-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from rmm-cu12==25.4.0) (25.4.0)
Requirement already satisfied: pynvml<13.0.0a0,>=12.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from dask-cudf-cu12==25.4.0) (12.0.0)
Requirement already satisfied: libcuvs-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from cuvs-cu12==25.4.*->cuml-cu12==25.4.0) (25.4.0)
Requirement already satisfied: click>=8.1 in ./cuml-test-env/lib/python3.10/site-packages (from dask-cuda==25.4.*->cuml-cu12==25.4.0) (8.1.8)
Requirement already satisfied: zict>=2.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from dask-cuda==25.4.*->cuml-cu12==25.4.0) (3.0.0)
Requirement already satisfied: libkvikio-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.0) (25.4.0)
Requirement already satisfied: nvidia-nvcomp-cu12==4.2.0.11 in ./cuml-test-env/lib/python3.10/site-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.0) (4.2.0.11)
Requirement already satisfied: rapids-logger==0.1.* in ./cuml-test-env/lib/python3.10/site-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.0) (0.1.1)
Requirement already satisfied: libraft-cu12==25.4.* in ./cuml-test-env/lib/python3.10/site-packages (from libcuml-cu12==25.4.*->cuml-cu12==25.4.0) (25.4.0)
Requirement already satisfied: distributed-ucxx-cu12==0.43.* in ./cuml-test-env/lib/python3.10/site-packages (from raft-dask-cu12==25.4.*->cuml-cu12==25.4.0) (0.43.0)
Requirement already satisfied: ucx-py-cu12==0.43.* in ./cuml-test-env/lib/python3.10/site-packages (from raft-dask-cu12==25.4.*->cuml-cu12==25.4.0) (0.43.0)
Requirement already satisfied: dask==2025.2.0 in ./cuml-test-env/lib/python3.10/site-packages (from rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (2025.2.0)
Requirement already satisfied: distributed==2025.2.0 in ./cuml-test-env/lib/python3.10/site-packages (from rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (2025.2.0)
Requirement already satisfied: cloudpickle>=3.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (3.1.1)
Requirement already satisfied: partd>=1.4.0 in ./cuml-test-env/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (1.4.2)
Requirement already satisfied: pyyaml>=5.3.1 in ./cuml-test-env/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (6.0.2)
Requirement already satisfied: toolz>=0.10.0 in ./cuml-test-env/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (1.0.0)
Requirement already satisfied: importlib_metadata>=4.13.0 in ./cuml-test-env/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (8.6.1)
Requirement already satisfied: jinja2>=2.10.3 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (3.1.6)
Requirement already satisfied: locket>=1.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (1.0.0)
Requirement already satisfied: msgpack>=1.0.2 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (1.1.0)
Requirement already satisfied: psutil>=5.8.0 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (7.0.0)
Requirement already satisfied: sortedcontainers>=2.0.5 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (2.4.0)
Requirement already satisfied: tblib>=1.6.0 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (3.1.0)
Requirement already satisfied: tornado>=6.2.0 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (6.4.2)
Requirement already satisfied: urllib3>=1.26.5 in ./cuml-test-env/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (2.4.0)
Requirement already satisfied: ucxx-cu12==0.43.* in ./cuml-test-env/lib/python3.10/site-packages (from distributed-ucxx-cu12==0.43.*->raft-dask-cu12==25.4.*->cuml-cu12==25.4.0) (0.43.0)
Requirement already satisfied: libucx-cu12<1.19,>=1.15.0 in ./cuml-test-env/lib/python3.10/site-packages (from ucx-py-cu12==0.43.*->raft-dask-cu12==25.4.*->cuml-cu12==25.4.0) (1.18.0)
Requirement already satisfied: libucxx-cu12==0.43.* in ./cuml-test-env/lib/python3.10/site-packages (from ucxx-cu12==0.43.*->distributed-ucxx-cu12==0.43.*->raft-dask-cu12==25.4.*->cuml-cu12==25.4.0) (0.43.0)
Requirement already satisfied: fastrlock>=0.5 in ./cuml-test-env/lib/python3.10/site-packages (from cupy-cuda12x) (0.8.3)
Requirement already satisfied: cuda-bindings~=12.8.0 in ./cuml-test-env/lib/python3.10/site-packages (from cuda-python<13.0a0,>=12.6.2->cudf-cu12==25.4.0) (12.8.0)
Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./cuml-test-env/lib/python3.10/site-packages (from numba<0.62.0a0,>=0.59.1->cudf-cu12==25.4.0) (0.43.0)
Requirement already satisfied: python-dateutil>=2.8.2 in ./cuml-test-env/lib/python3.10/site-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.0) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./cuml-test-env/lib/python3.10/site-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.0) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in ./cuml-test-env/lib/python3.10/site-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.0) (2025.2)
Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from pynvml<13.0.0a0,>=12.0.0->dask-cudf-cu12==25.4.0) (12.570.86)
Requirement already satisfied: nvidia-nvjitlink-cu12 in ./cuml-test-env/lib/python3.10/site-packages (from nvidia-cusolver-cu12->cuml-cu12==25.4.0) (12.4.127)
Requirement already satisfied: markdown-it-py>=2.2.0 in ./cuml-test-env/lib/python3.10/site-packages (from rich->cudf-cu12==25.4.0) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./cuml-test-env/lib/python3.10/site-packages (from rich->cudf-cu12==25.4.0) (2.19.1)
Requirement already satisfied: mdurl~=0.1 in ./cuml-test-env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12==25.4.0) (0.1.2)
Requirement already satisfied: six>=1.5 in ./cuml-test-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.0) (1.17.0)
Requirement already satisfied: zipp>=3.20 in ./cuml-test-env/lib/python3.10/site-packages (from importlib_metadata>=4.13.0->dask==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (3.21.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./cuml-test-env/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed==2025.2.0->rapids-dask-dependency==25.4.*->cuml-cu12==25.4.0) (3.0.2)
Installing collected packages: dask-cuda
Successfully installed dask-cuda-25.4.0
Requirement already satisfied: numexpr in ./cuml-test-env/lib/python3.10/site-packages (2.10.2)
Requirement already satisfied: bottleneck in ./cuml-test-env/lib/python3.10/site-packages (1.4.2)
Requirement already satisfied: numpy<1.25 in ./cuml-test-env/lib/python3.10/site-packages (1.24.4)
Requirement already satisfied: scipy in ./cuml-test-env/lib/python3.10/site-packages (1.15.2)
cuML is working
job is running on xgph1, started at Wed Apr 16 06:20:19 PM +08 2025
Running inference with model: lightgbm_tfidf
\n--- Installing packages ---\n
Requirement already satisfied: torch in ./cuml-test-env/lib/python3.10/site-packages (2.6.0)
Requirement already satisfied: pandas in ./cuml-test-env/lib/python3.10/site-packages (2.2.3)
Requirement already satisfied: transformers in ./cuml-test-env/lib/python3.10/site-packages (4.51.2)
Requirement already satisfied: scikit-learn in ./cuml-test-env/lib/python3.10/site-packages (1.6.1)
Requirement already satisfied: joblib in ./cuml-test-env/lib/python3.10/site-packages (1.4.2)
Requirement already satisfied: lightgbm in ./cuml-test-env/lib/python3.10/site-packages (4.6.0)
Requirement already satisfied: optuna in ./cuml-test-env/lib/python3.10/site-packages (4.2.1)
Requirement already satisfied: xgboost in ./cuml-test-env/lib/python3.10/site-packages (3.0.0)
Requirement already satisfied: torch-tb-profiler in ./cuml-test-env/lib/python3.10/site-packages (0.4.3)
Requirement already satisfied: tensorboard in ./cuml-test-env/lib/python3.10/site-packages (2.19.0)
Requirement already satisfied: filelock in ./cuml-test-env/lib/python3.10/site-packages (from torch) (3.18.0)
Requirement already satisfied: typing-extensions>=4.10.0 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (4.13.2)
Requirement already satisfied: networkx in ./cuml-test-env/lib/python3.10/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in ./cuml-test-env/lib/python3.10/site-packages (from torch) (2025.3.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.4.127)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.4.127)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.4.127)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.4.5.8)
Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (11.2.1.3)
Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (10.3.5.147)
Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (11.6.1.9)
Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.3.1.170)
Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (0.6.2)
Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (2.21.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.4.127)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (12.4.127)
Requirement already satisfied: triton==3.2.0 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (3.2.0)
Requirement already satisfied: sympy==1.13.1 in ./cuml-test-env/lib/python3.10/site-packages (from torch) (1.13.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./cuml-test-env/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)
Requirement already satisfied: numpy>=1.22.4 in ./cuml-test-env/lib/python3.10/site-packages (from pandas) (1.24.4)
Requirement already satisfied: python-dateutil>=2.8.2 in ./cuml-test-env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./cuml-test-env/lib/python3.10/site-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in ./cuml-test-env/lib/python3.10/site-packages (from pandas) (2025.2)
Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (0.30.2)
Requirement already satisfied: packaging>=20.0 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (24.2)
Requirement already satisfied: pyyaml>=5.1 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (2024.11.6)
Requirement already satisfied: requests in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (2.32.3)
Requirement already satisfied: tokenizers<0.22,>=0.21 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (0.21.1)
Requirement already satisfied: safetensors>=0.4.3 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (0.5.3)
Requirement already satisfied: tqdm>=4.27 in ./cuml-test-env/lib/python3.10/site-packages (from transformers) (4.67.1)
Requirement already satisfied: scipy>=1.6.0 in ./cuml-test-env/lib/python3.10/site-packages (from scikit-learn) (1.15.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in ./cuml-test-env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)
Requirement already satisfied: alembic>=1.5.0 in ./cuml-test-env/lib/python3.10/site-packages (from optuna) (1.15.2)
Requirement already satisfied: colorlog in ./cuml-test-env/lib/python3.10/site-packages (from optuna) (6.9.0)
Requirement already satisfied: sqlalchemy>=1.4.2 in ./cuml-test-env/lib/python3.10/site-packages (from optuna) (2.0.40)
Requirement already satisfied: absl-py>=0.4 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (2.2.2)
Requirement already satisfied: grpcio>=1.48.2 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (1.71.0)
Requirement already satisfied: markdown>=2.6.8 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (3.8)
Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (6.30.2)
Requirement already satisfied: setuptools>=41.0.0 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (78.1.0)
Requirement already satisfied: six>1.9 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (1.17.0)
Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (0.7.2)
Requirement already satisfied: werkzeug>=1.0.1 in ./cuml-test-env/lib/python3.10/site-packages (from tensorboard) (3.1.3)
Requirement already satisfied: Mako in ./cuml-test-env/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.10)
Requirement already satisfied: greenlet>=1 in ./cuml-test-env/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)
Requirement already satisfied: MarkupSafe>=2.1.1 in ./cuml-test-env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)
Requirement already satisfied: charset-normalizer<4,>=2 in ./cuml-test-env/lib/python3.10/site-packages (from requests->transformers) (3.4.1)
Requirement already satisfied: idna<4,>=2.5 in ./cuml-test-env/lib/python3.10/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./cuml-test-env/lib/python3.10/site-packages (from requests->transformers) (2.4.0)
Requirement already satisfied: certifi>=2017.4.17 in ./cuml-test-env/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)
\n--- Finished installing packages, starting model inference ---\n
Running LightGBM TF-IDF model inference...
device: cuda
Using device: cuda
Model size: 0.47 MB
Loaded model from /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/inference_scripts/../models/lightgbm_tfidf_tuned_kl_classifier.txt

--- Testing with batch size: 32 ---
Initial GPU memory: 0.00 MB
Warming up...
GPU memory after warmup: 1.23 MB

Profiler Stats Summary:
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        98.09%       15.911s        98.10%       15.914s      59.159ms       0.000us         0.00%     109.953us       0.409us           0 b           0 b           0 b           0 b           269  
                                       batch_processing         0.27%      43.014ms         1.90%     307.728ms       1.148ms       0.000us         0.00%       9.458ms      35.290us           0 b           0 b      10.63 Mb           0 b           268  
                                        model_inference         1.27%     205.615ms         1.42%     230.385ms     859.646us       0.000us         0.00%       1.937ms       7.229us           0 b           0 b    -154.30 Mb    -154.30 Mb           268  
                                               aten::to         0.01%       1.862ms         0.17%      27.133ms      25.311us       0.000us         0.00%       7.437ms       6.938us           0 b           0 b     164.92 Mb           0 b          1072  
                                         aten::_to_copy         0.01%       1.737ms         0.16%      25.271ms      94.294us       0.000us         0.00%       7.437ms      27.751us           0 b           0 b     164.92 Mb           0 b           268  
                                            aten::copy_         0.02%       2.854ms         0.09%      15.324ms      57.178us       7.437ms        29.02%       7.437ms      27.751us           0 b           0 b           0 b           0 b           268  
                                  cudaStreamSynchronize         0.06%      10.399ms         0.06%      10.399ms      12.934us      83.234us         0.32%      83.234us       0.104us           0 b           0 b           0 b           0 b           804  
                                        cudaMemcpyAsync         0.06%       9.008ms         0.06%       9.008ms      16.806us     109.953us         0.43%     109.953us       0.205us           0 b           0 b           0 b           0 b           536  
                                    aten::empty_strided         0.02%       3.851ms         0.05%       8.210ms      30.635us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     164.92 Mb     164.92 Mb           268  
                                        cudaStreamQuery         0.05%       7.861ms         0.05%       7.861ms       0.901us       1.330ms         5.19%       1.330ms       0.152us           0 b           0 b           0 b           0 b          8723  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 16.222s
Self CUDA time total: 25.633ms

GPU peak memory: 13.58 MB
GPU memory used: 13.58 MB
Memory summary:
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1264 KiB |  13904 KiB | 170146 KiB | 168882 KiB |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 KiB |
|       from small pool |   1264 KiB |  13904 KiB | 170146 KiB | 168882 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1264 KiB |  13904 KiB | 170146 KiB | 168882 KiB |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 KiB |
|       from small pool |   1264 KiB |  13904 KiB | 170146 KiB | 168882 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1263 KiB |  13895 KiB | 170045 KiB | 168782 KiB |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 KiB |
|       from small pool |   1263 KiB |  13895 KiB | 170045 KiB | 168782 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  14336 KiB |  16384 KiB |  43008 KiB |  28672 KiB |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 KiB |
|       from small pool |  14336 KiB |  16384 KiB |  43008 KiB |  28672 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    784 KiB |   9432 KiB | 185978 KiB | 185194 KiB |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 KiB |
|       from small pool |    784 KiB |   9432 KiB | 185978 KiB | 185194 KiB |
|---------------------------------------------------------------------------|
| Allocations           |       2    |      22    |     270    |     268    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |      22    |     270    |     268    |
|---------------------------------------------------------------------------|
| Active allocs         |       2    |      22    |     270    |     268    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       2    |      22    |     270    |     268    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       7    |       8    |      21    |      14    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       7    |       8    |      21    |      14    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       1    |      13    |     135    |     134    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       1    |      13    |     135    |     134    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

CUDA Time (profiler): 0.04 ms
CUDA Memory usage (profiler): 13.58 MB
Total inference time: 16.4209 seconds
Average latency per batch: 0.04 ms
Average latency per sample: 0.00 ms
Throughput: 520.74 samples/second
CPU Memory usage (profiler): 0.00 MB
Accuracy: 0.8172
F1 Score: 0.8166
Full profiler trace saved to: /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_32/trace.json
View with TensorBoard: tensorboard --logdir=/home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_32

--- Testing with batch size: 64 ---
Initial GPU memory: 0.62 MB
Warming up...
GPU memory after warmup: 2.47 MB

Profiler Stats Summary:
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        99.01%       15.897s        99.03%       15.900s     117.780ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           135  
                                       batch_processing         0.14%      22.937ms         0.97%     156.073ms       1.165ms       0.000us         0.00%       7.090ms      52.910us           0 b           0 b      14.32 Mb           0 b           134  
                                        model_inference         0.63%     101.390ms         0.71%     114.357ms     853.407us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    -151.31 Mb    -151.31 Mb           134  
                                               aten::to         0.01%     987.288us         0.10%      15.769ms      29.419us       0.000us         0.00%       7.090ms      13.227us           0 b           0 b     165.63 Mb           0 b           536  
                                         aten::_to_copy         0.01%     890.366us         0.09%      14.781ms     110.309us       0.000us         0.00%       7.090ms      52.910us           0 b           0 b     165.63 Mb           0 b           134  
                                            aten::copy_         0.01%       1.501ms         0.07%      11.454ms      85.476us       7.090ms        43.52%       7.090ms      52.910us           0 b           0 b           0 b           0 b           134  
                                  cudaStreamSynchronize         0.05%       8.620ms         0.05%       8.620ms      21.443us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           402  
                                        cudaMemcpyAsync         0.03%       4.896ms         0.03%       4.896ms      18.268us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           268  
                                        cudaStreamQuery         0.02%       3.997ms         0.02%       3.997ms       0.893us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          4478  
                                       cudaLaunchKernel         0.02%       2.846ms         0.02%       2.846ms      21.239us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           134  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 16.056s
Self CUDA time total: 16.292ms

GPU peak memory: 26.17 MB
GPU memory used: 25.55 MB
Memory summary:
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3790 KiB |  26797 KiB | 342281 KiB | 338490 KiB |
|       from large pool |   3790 KiB |  26797 KiB | 171364 KiB | 167574 KiB |
|       from small pool |      0 KiB |    770 KiB | 170916 KiB | 170916 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   3790 KiB |  26797 KiB | 342281 KiB | 338490 KiB |
|       from large pool |   3790 KiB |  26797 KiB | 171364 KiB | 167574 KiB |
|       from small pool |      0 KiB |    770 KiB | 170916 KiB | 170916 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3789 KiB |  26528 KiB | 341353 KiB | 337564 KiB |
|       from large pool |   3789 KiB |  26528 KiB | 170538 KiB | 166749 KiB |
|       from small pool |      0 KiB |    769 KiB | 170815 KiB | 170815 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  43008 KiB |  43008 KiB |  86016 KiB |  43008 KiB |
|       from large pool |  40960 KiB |  40960 KiB |  40960 KiB |      0 KiB |
|       from small pool |   2048 KiB |   2048 KiB |  45056 KiB |  43008 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  37169 KiB |  37169 KiB | 393895 KiB | 356726 KiB |
|       from large pool |  37169 KiB |  37169 KiB | 206007 KiB | 168837 KiB |
|       from small pool |      0 KiB |   1278 KiB | 187888 KiB | 187888 KiB |
|---------------------------------------------------------------------------|
| Allocations           |       3    |      21    |     406    |     403    |
|       from large pool |       3    |      21    |     135    |     132    |
|       from small pool |       0    |       1    |     271    |     271    |
|---------------------------------------------------------------------------|
| Active allocs         |       3    |      21    |     406    |     403    |
|       from large pool |       3    |      21    |     135    |     132    |
|       from small pool |       0    |       1    |     271    |     271    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       3    |       3    |      24    |      21    |
|       from large pool |       2    |       2    |       2    |       0    |
|       from small pool |       1    |       1    |      22    |      21    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       3    |       9    |     207    |     204    |
|       from large pool |       3    |       9    |      71    |      68    |
|       from small pool |       0    |       1    |     136    |     136    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

CUDA Time (profiler): 0.03 ms
CUDA Memory usage (profiler): 25.55 MB
Total inference time: 16.1689 seconds
Average latency per batch: 0.03 ms
Average latency per sample: 0.00 ms
Throughput: 528.85 samples/second
CPU Memory usage (profiler): 0.00 MB
Accuracy: 0.8172
F1 Score: 0.8166
Full profiler trace saved to: /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_64/trace.json
View with TensorBoard: tensorboard --logdir=/home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_64

--- Testing with batch size: 128 ---
Initial GPU memory: 1.23 MB
Warming up...
GPU memory after warmup: 4.93 MB

Profiler Stats Summary:
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        99.39%       15.870s        99.42%       15.875s     233.453ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            68  
                                       batch_processing         0.10%      15.264ms         0.58%      92.996ms       1.388ms       0.000us         0.00%       6.960ms     103.875us           0 b           0 b      29.61 Mb           0 b            67  
                                        model_inference         0.35%      56.471ms         0.40%      63.752ms     951.524us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    -137.01 Mb    -137.01 Mb            67  
                                               aten::to         0.00%     537.745us         0.08%      12.297ms      45.885us       0.000us         0.00%       6.960ms      25.969us           0 b           0 b     166.62 Mb           0 b           268  
                                         aten::_to_copy         0.00%     482.689us         0.07%      11.759ms     175.514us       0.000us         0.00%       6.960ms     103.875us           0 b           0 b     166.62 Mb           0 b            67  
                                            aten::copy_         0.01%     820.704us         0.06%       9.582ms     143.010us       6.960ms        58.74%       6.960ms     103.875us           0 b           0 b           0 b           0 b            67  
                                  cudaStreamSynchronize         0.05%       7.714ms         0.05%       7.714ms      38.378us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           201  
                                          cudaHostAlloc         0.03%       4.143ms         0.03%       4.143ms       1.036ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  
                                        cudaMemcpyAsync         0.02%       2.942ms         0.02%       2.942ms      21.953us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           134  
                                        cudaStreamQuery         0.01%       2.036ms         0.01%       2.036ms       0.900us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          2263  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 15.968s
Self CUDA time total: 11.847ms

GPU peak memory: 44.67 MB
GPU memory used: 43.44 MB
Memory summary:
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5053 KiB |  45745 KiB | 517949 KiB | 512896 KiB |
|       from large pool |   5053 KiB |  45745 KiB | 347033 KiB | 341980 KiB |
|       from small pool |      0 KiB |      0 KiB | 170916 KiB | 170916 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   5053 KiB |  45745 KiB | 517949 KiB | 512896 KiB |
|       from large pool |   5053 KiB |  45745 KiB | 347033 KiB | 341980 KiB |
|       from small pool |      0 KiB |      0 KiB | 170916 KiB | 170916 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5053 KiB |  45477 KiB | 515188 KiB | 510135 KiB |
|       from large pool |   5053 KiB |  45477 KiB | 344373 KiB | 339320 KiB |
|       from small pool |      0 KiB |      0 KiB | 170815 KiB | 170815 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  61440 KiB |  61440 KiB | 126976 KiB |  65536 KiB |
|       from large pool |  61440 KiB |  61440 KiB |  81920 KiB |  20480 KiB |
|       from small pool |      0 KiB |      0 KiB |  45056 KiB |  45056 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  15427 KiB |  51334 KiB | 597892 KiB | 582465 KiB |
|       from large pool |  15427 KiB |  51334 KiB | 410003 KiB | 394576 KiB |
|       from small pool |      0 KiB |      0 KiB | 187888 KiB | 187888 KiB |
|---------------------------------------------------------------------------|
| Allocations           |       2    |      18    |     475    |     473    |
|       from large pool |       2    |      18    |     204    |     202    |
|       from small pool |       0    |       0    |     271    |     271    |
|---------------------------------------------------------------------------|
| Active allocs         |       2    |      18    |     475    |     473    |
|       from large pool |       2    |      18    |     204    |     202    |
|       from small pool |       0    |       0    |     271    |     271    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       3    |       3    |      26    |      23    |
|       from large pool |       3    |       3    |       4    |       1    |
|       from small pool |       0    |       0    |      22    |      22    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |      10    |     254    |     252    |
|       from large pool |       2    |      10    |     118    |     116    |
|       from small pool |       0    |       0    |     136    |     136    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

CUDA Time (profiler): 0.04 ms
CUDA Memory usage (profiler): 43.44 MB
Total inference time: 16.0409 seconds
Average latency per batch: 0.04 ms
Average latency per sample: 0.00 ms
Throughput: 533.07 samples/second
CPU Memory usage (profiler): 0.00 MB
Accuracy: 0.8172
F1 Score: 0.8166
Full profiler trace saved to: /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_128/trace.json
View with TensorBoard: tensorboard --logdir=/home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_128

--- Testing with batch size: 256 ---
Initial GPU memory: 2.47 MB
Warming up...
GPU memory after warmup: 9.87 MB

Profiler Stats Summary:
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        99.60%       16.018s        99.63%       16.022s     457.775ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            35  
                                       batch_processing         0.06%      10.206ms         0.37%      60.203ms       1.771ms       0.000us         0.00%       6.891ms     202.672us           0 b           0 b      36.53 Mb           0 b            34  
                                        model_inference         0.20%      31.541ms         0.22%      35.832ms       1.054ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b    -130.13 Mb    -130.13 Mb            34  
                                               aten::to         0.00%     342.053us         0.08%      12.858ms      94.544us       0.000us         0.00%       6.891ms      50.668us           0 b           0 b     166.66 Mb           0 b           136  
                                         aten::_to_copy         0.00%     265.090us         0.08%      12.516ms     368.114us       0.000us         0.00%       6.891ms     202.672us           0 b           0 b     166.66 Mb           0 b            34  
                                            aten::copy_         0.00%     444.905us         0.06%      10.274ms     302.188us       6.891ms        71.33%       6.891ms     202.672us           0 b           0 b           0 b           0 b            34  
                                  cudaStreamSynchronize         0.05%       7.299ms         0.05%       7.299ms      71.557us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           102  
                                          cudaHostAlloc         0.03%       4.041ms         0.03%       4.041ms       2.021ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  
                                        cudaMemcpyAsync         0.02%       3.574ms         0.02%       3.574ms      52.559us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            68  
                                    aten::empty_strided         0.00%     734.418us         0.01%       1.976ms      58.130us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     166.66 Mb     166.66 Mb            34  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 16.082s
Self CUDA time total: 9.661ms

GPU peak memory: 69.61 MB
GPU memory used: 67.14 MB
Memory summary:
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  10106 KiB |  71278 KiB | 698714 KiB | 688608 KiB |
|       from large pool |  10106 KiB |  71278 KiB | 527797 KiB | 517691 KiB |
|       from small pool |      0 KiB |      0 KiB | 170916 KiB | 170916 KiB |
|---------------------------------------------------------------------------|
| Active memory         |  10106 KiB |  71278 KiB | 698714 KiB | 688608 KiB |
|       from large pool |  10106 KiB |  71278 KiB | 527797 KiB | 517691 KiB |
|       from small pool |      0 KiB |      0 KiB | 170916 KiB | 170916 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |  10106 KiB |  70742 KiB | 694076 KiB | 683970 KiB |
|       from large pool |  10106 KiB |  70742 KiB | 523261 KiB | 513155 KiB |
|       from small pool |      0 KiB |      0 KiB | 170815 KiB | 170815 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  81920 KiB |  81920 KiB | 229376 KiB | 147456 KiB |
|       from large pool |  81920 KiB |  81920 KiB | 184320 KiB | 102400 KiB |
|       from small pool |      0 KiB |      0 KiB |  45056 KiB |  45056 KiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  10374 KiB |  51602 KiB |    805 MiB |    795 MiB |
|       from large pool |  10374 KiB |  51602 KiB |    622 MiB |    611 MiB |
|       from small pool |      0 KiB |      0 KiB |    183 MiB |    183 MiB |
|---------------------------------------------------------------------------|
| Allocations           |       2    |      14    |     511    |     509    |
|       from large pool |       2    |      14    |     240    |     238    |
|       from small pool |       0    |       0    |     271    |     271    |
|---------------------------------------------------------------------------|
| Active allocs         |       2    |      14    |     511    |     509    |
|       from large pool |       2    |      14    |     240    |     238    |
|       from small pool |       0    |       0    |     271    |     271    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |      31    |      27    |
|       from large pool |       4    |       4    |       9    |       5    |
|       from small pool |       0    |       0    |      22    |      22    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       2    |       8    |     275    |     273    |
|       from large pool |       2    |       8    |     139    |     137    |
|       from small pool |       0    |       0    |     136    |     136    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

CUDA Time (profiler): 0.04 ms
CUDA Memory usage (profiler): 67.14 MB
Total inference time: 16.1431 seconds
Average latency per batch: 0.04 ms
Average latency per sample: 0.00 ms
Throughput: 529.70 samples/second
CPU Memory usage (profiler): 0.00 MB
Accuracy: 0.8172
F1 Score: 0.8166
Full profiler trace saved to: /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_256/trace.json
View with TensorBoard: tensorboard --logdir=/home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profile_batch_256

Results saved to /home/j/jiaxi/CS4248_project_folder/Sarcasm-Detection-main/profiler_results/lightgbm_tfidf/profiler_inference_metrics.csv

=== SUMMARY ===
Model size: 0.47 MB

Best throughput configuration:
  Batch size: 128.0
  Throughput: 533.07 samples/second
  Latency per sample: 0.00 ms
  CPU Memory usage: 0.00 MB
  GPU Memory usage: 43.44 MB

Best latency configuration:
  Batch size: 256.0
  Latency per sample: 0.00 ms
  Throughput: 529.70 samples/second
  CPU Memory usage: 0.00 MB
  GPU Memory usage: 67.14 MB

Job completed at Wed Apr 16 06:21:54 PM +08 2025

total execution time: 93 seconds

